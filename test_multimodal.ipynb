{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from opr.testing import test\n",
    "from opr.utils import parse_device\n",
    "from opr.modules import Concat\n",
    "\n",
    "from src.models import LateFusionModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expreriment: nclt_camera1_lidar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating test set descriptors:   0%|          | 0/86 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    }
   ],
   "source": [
    "DEVICE = parse_device(\"cuda\")\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DATASET = \"nclt\"\n",
    "\n",
    "DATASET_DIR = {\n",
    "    \"oxford\": \"/home/docker_mssplace/Datasets/pnvlad_oxford_robotcar_full\",\n",
    "    \"nclt\": \"/home/docker_mssplace/Datasets/NCLT_preprocessed\",\n",
    "}\n",
    "\n",
    "MODALITIES_LIST = [\n",
    "    # \"all_camera_lidar\",\n",
    "    # \"all_camera_semantic_lidar\",\n",
    "    # \"all_camera_semantic_text_lidar\",\n",
    "    # \"all_camera_semantic_text\",\n",
    "    # \"all_camera_semantic\",\n",
    "    # \"all_camera_text_lidar\",\n",
    "    # \"all_camera_text\",\n",
    "    \"camera1_lidar\",\n",
    "]\n",
    "\n",
    "for MODALITIES in MODALITIES_LIST:\n",
    "    i = 4 if DATASET == \"oxford\" else 5\n",
    "\n",
    "    IMAGE_MODEL = f\"{DATASET}_camera1_exp.pth\" if \"camera\" in MODALITIES else None\n",
    "    SEMANTIC_MODEL = None # f\"{DATASET}_camera1_add.pth\" if \"semantic\" in MODALITIES else None\n",
    "    TEXT_MODEL = None # f\"{DATASET}_text{i}_clip-base-mlp-add.pth\" if \"text\" in MODALITIES else None\n",
    "    LIDAR_MODEL = f\"{DATASET}_lidar_exp.pth\" if \"lidar\" in MODALITIES else None\n",
    "\n",
    "    def load_model(checkpoint_name: str) -> nn.Module:\n",
    "        checkpoint_name = Path(checkpoint_name)\n",
    "        checkpoint = torch.load(\"./checkpoints\" / checkpoint_name)\n",
    "        model_cfg = OmegaConf.create(checkpoint[\"config\"][\"model\"])\n",
    "        model = instantiate(model_cfg)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def load_dataloader(dataset_name: str, modalities: str) -> DataLoader:\n",
    "        dataset_cfg = OmegaConf.load(Path(\"configs\") / \"dataset\" / dataset_name / (modalities + \".yaml\"))\n",
    "        dataset_cfg.dataset_root = DATASET_DIR[dataset_name]\n",
    "        dataset = instantiate(dataset_cfg, subset=\"test\")\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            collate_fn=dataset.collate_fn,\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    dataloader = load_dataloader(DATASET, MODALITIES)\n",
    "    image_model = load_model(IMAGE_MODEL) if IMAGE_MODEL else None\n",
    "    semantic_model = load_model(SEMANTIC_MODEL) if SEMANTIC_MODEL else None\n",
    "    text_model = load_model(TEXT_MODEL) if TEXT_MODEL else None\n",
    "    lidar_model = load_model(LIDAR_MODEL) if LIDAR_MODEL else None\n",
    "\n",
    "    concat_model = LateFusionModel(\n",
    "        image_model,\n",
    "        semantic_model,\n",
    "        text_model,\n",
    "        lidar_model,\n",
    "        fusion_module=Concat()\n",
    "    )\n",
    "    concat_model.eval()\n",
    "    concat_model = concat_model.to(DEVICE)\n",
    "\n",
    "    print(f\"Expreriment: {DATASET}_{MODALITIES}\")\n",
    "\n",
    "    mean_recall_at_n, mean_recall_at_one_percent, mean_top1_distance = test(\n",
    "        concat_model, dataloader\n",
    "    )\n",
    "    metrics = {\n",
    "        'dataset': DATASET,\n",
    "        \"modality\": MODALITIES,\n",
    "        'exp_name': \"concat\",\n",
    "        'R@1': mean_recall_at_n[0],\n",
    "        'R@3': mean_recall_at_n[2],\n",
    "        'R@5': mean_recall_at_n[4],\n",
    "        'R@10': mean_recall_at_n[9],\n",
    "        'R@1%': mean_recall_at_one_percent,\n",
    "        'mean_top1_distance': mean_top1_distance,\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics, index=[0])\n",
    "\n",
    "    if not Path(f\"{DATASET}_{MODALITIES}_metrics.csv\").exists():\n",
    "        metrics_df.to_csv(f\"{DATASET}_{MODALITIES}_metrics.csv\", index=False)\n",
    "    else:\n",
    "        print(\"Metrics csv exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
